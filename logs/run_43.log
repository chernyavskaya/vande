setGPU: Setting GPU to: 0
Using TensorFlow backend.
/afs/cern.ch/work/k/kiwoznia/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/afs/cern.ch/work/k/kiwoznia/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/afs/cern.ch/work/k/kiwoznia/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/afs/cern.ch/work/k/kiwoznia/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/afs/cern.ch/work/k/kiwoznia/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/afs/cern.ch/work/k/kiwoznia/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
/afs/cern.ch/work/k/kiwoznia/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/afs/cern.ch/work/k/kiwoznia/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/afs/cern.ch/work/k/kiwoznia/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/afs/cern.ch/work/k/kiwoznia/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/afs/cern.ch/work/k/kiwoznia/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/afs/cern.ch/work/k/kiwoznia/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
=== reading images from  /eos/user/k/kiwoznia/data/VAE_data/VAE_check/images/qcd_side_new.h5  ===
read  1200714  jet 1 images and  1200714  jet 2 images
WARNING:tensorflow:From /afs/cern.ch/work/k/kiwoznia/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4074: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.

Model: "encoder"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
encoder_input (InputLayer)      (None, 32, 32, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 30, 30, 4)    40          encoder_input[0][0]              
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 28, 28, 8)    296         conv2d_1[0][0]                   
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 26, 26, 12)   876         conv2d_2[0][0]                   
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 13, 13, 12)   0           conv2d_3[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 2028)         0           average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 119)          241451      flatten_1[0][0]                  
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 48)           5760        dense_1[0][0]                    
__________________________________________________________________________________________________
z_mean (Dense)                  (None, 10)           490         dense_2[0][0]                    
__________________________________________________________________________________________________
z_log_var (Dense)               (None, 10)           490         dense_2[0][0]                    
__________________________________________________________________________________________________
z (Lambda)                      (None, 10)           0           z_mean[0][0]                     
                                                                 z_log_var[0][0]                  
==================================================================================================
Total params: 249,403
Trainable params: 249,403
Non-trainable params: 0
__________________________________________________________________________________________________
Model: "decoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
z_sampling (InputLayer)      (None, 10)                0         
_________________________________________________________________
dense_3 (Dense)              (None, 48)                528       
_________________________________________________________________
dense_4 (Dense)              (None, 119)               5831      
_________________________________________________________________
dense_5 (Dense)              (None, 2028)              243360    
_________________________________________________________________
reshape_1 (Reshape)          (None, 13, 13, 12)        0         
_________________________________________________________________
up_sampling2d_1 (UpSampling2 (None, 26, 26, 12)        0         
_________________________________________________________________
conv2d_transpose_1 (Conv2DTr (None, 28, 28, 12)        1308      
_________________________________________________________________
conv2d_transpose_2 (Conv2DTr (None, 30, 30, 8)         872       
_________________________________________________________________
conv2d_transpose_3 (Conv2DTr (None, 32, 32, 4)         292       
_________________________________________________________________
decoder_output (Conv2DTransp (None, 32, 32, 1)         37        
=================================================================
Total params: 252,228
Trainable params: 252,228
Non-trainable params: 0
_________________________________________________________________
Model: "vae"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
encoder_input (InputLayer)   (None, 32, 32, 1)         0         
_________________________________________________________________
encoder (Model)              [(None, 10), (None, 10),  249403    
_________________________________________________________________
decoder (Model)              (None, 32, 32, 1)         252228    
=================================================================
Total params: 501,631
Trainable params: 501,631
Non-trainable params: 0
_________________________________________________________________
WARNING:tensorflow:From /afs/cern.ch/work/k/kiwoznia/.local/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
2020-06-01 01:10:29.860992: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-06-01 01:10:31.160933: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2020-06-01 01:10:36.550757: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x122265d0 executing computations on platform CUDA. Devices:
2020-06-01 01:10:36.550830: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): GeForce GTX 1080 Ti, Compute Capability 6.1
2020-06-01 01:10:36.645826: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2200095000 Hz
2020-06-01 01:10:36.649409: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0xafaef10 executing computations on platform Host. Devices:
2020-06-01 01:10:36.649464: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2020-06-01 01:10:36.651711: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:04:00.0
2020-06-01 01:10:36.979942: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2020-06-01 01:10:37.071929: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2020-06-01 01:10:37.676652: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2020-06-01 01:10:37.724291: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2020-06-01 01:10:37.830660: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2020-06-01 01:10:38.365363: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2020-06-01 01:10:39.390833: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2020-06-01 01:10:39.394701: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2020-06-01 01:10:39.401820: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2020-06-01 01:10:39.407021: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-06-01 01:10:39.407061: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2020-06-01 01:10:39.407085: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2020-06-01 01:10:39.410845: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10481 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:04:00.0, compute capability: 6.1)
WARNING:tensorflow:From /afs/cern.ch/work/k/kiwoznia/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

Train on 1801071 samples, validate on 600357 samples
WARNING:tensorflow:From /afs/cern.ch/work/k/kiwoznia/.local/lib/python3.6/site-packages/keras/callbacks/tensorboard_v1.py:198: The name tf.summary.histogram is deprecated. Please use tf.compat.v1.summary.histogram instead.

WARNING:tensorflow:From /afs/cern.ch/work/k/kiwoznia/.local/lib/python3.6/site-packages/keras/callbacks/tensorboard_v1.py:200: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.

WARNING:tensorflow:From /afs/cern.ch/work/k/kiwoznia/.local/lib/python3.6/site-packages/keras/callbacks/tensorboard_v1.py:203: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.

Epoch 1/100
2020-06-01 01:10:57.487384: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2020-06-01 01:10:58.408385: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
 - 272s - loss: 0.1129 - mse_loss: 0.0773 - loss_1: 3.5588 - val_loss: 0.1009 - val_mse_loss: 0.0603 - val_loss_1: 4.0584
WARNING:tensorflow:From /afs/cern.ch/work/k/kiwoznia/.local/lib/python3.6/site-packages/keras/callbacks/tensorboard_v1.py:343: The name tf.Summary is deprecated. Please use tf.compat.v1.Summary instead.

Epoch 2/100
 - 256s - loss: 0.0991 - mse_loss: 0.0586 - loss_1: 4.0497 - val_loss: 0.0980 - val_mse_loss: 0.0574 - val_loss_1: 4.0571
Epoch 3/100
 - 258s - loss: 0.0978 - mse_loss: 0.0571 - loss_1: 4.0728 - val_loss: 0.0976 - val_mse_loss: 0.0563 - val_loss_1: 4.1306
Epoch 4/100
 - 256s - loss: 0.0972 - mse_loss: 0.0563 - loss_1: 4.0835 - val_loss: 0.0969 - val_mse_loss: 0.0559 - val_loss_1: 4.1053
Epoch 5/100
 - 258s - loss: 0.0968 - mse_loss: 0.0559 - loss_1: 4.0941 - val_loss: 0.0968 - val_mse_loss: 0.0558 - val_loss_1: 4.0991
Epoch 6/100
 - 258s - loss: 0.0965 - mse_loss: 0.0555 - loss_1: 4.1001 - val_loss: 0.0964 - val_mse_loss: 0.0546 - val_loss_1: 4.1772
Epoch 7/100
 - 256s - loss: 0.0963 - mse_loss: 0.0553 - loss_1: 4.0983 - val_loss: 0.0963 - val_mse_loss: 0.0547 - val_loss_1: 4.1570
Epoch 8/100
 - 256s - loss: 0.0961 - mse_loss: 0.0550 - loss_1: 4.1105 - val_loss: 0.0963 - val_mse_loss: 0.0553 - val_loss_1: 4.0930
Epoch 9/100
 - 257s - loss: 0.0959 - mse_loss: 0.0548 - loss_1: 4.1154 - val_loss: 0.0962 - val_mse_loss: 0.0545 - val_loss_1: 4.1652
Epoch 10/100
 - 255s - loss: 0.0958 - mse_loss: 0.0547 - loss_1: 4.1129 - val_loss: 0.0960 - val_mse_loss: 0.0558 - val_loss_1: 4.0182
Epoch 11/100
 - 257s - loss: 0.0958 - mse_loss: 0.0546 - loss_1: 4.1220 - val_loss: 0.0958 - val_mse_loss: 0.0547 - val_loss_1: 4.1116
Epoch 12/100
 - 255s - loss: 0.0957 - mse_loss: 0.0544 - loss_1: 4.1307 - val_loss: 0.0957 - val_mse_loss: 0.0549 - val_loss_1: 4.0780
Epoch 13/100
 - 256s - loss: 0.0956 - mse_loss: 0.0543 - loss_1: 4.1301 - val_loss: 0.0954 - val_mse_loss: 0.0538 - val_loss_1: 4.1659
Epoch 14/100
 - 256s - loss: 0.0955 - mse_loss: 0.0542 - loss_1: 4.1292 - val_loss: 0.0956 - val_mse_loss: 0.0541 - val_loss_1: 4.1503
Epoch 15/100
 - 255s - loss: 0.0954 - mse_loss: 0.0541 - loss_1: 4.1334 - val_loss: 0.0954 - val_mse_loss: 0.0545 - val_loss_1: 4.0919

Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.
Epoch 16/100
 - 256s - loss: 0.0942 - mse_loss: 0.0528 - loss_1: 4.1363 - val_loss: 0.0941 - val_mse_loss: 0.0526 - val_loss_1: 4.1440
Epoch 17/100
 - 256s - loss: 0.0940 - mse_loss: 0.0525 - loss_1: 4.1489 - val_loss: 0.0940 - val_mse_loss: 0.0527 - val_loss_1: 4.1300
Epoch 18/100
 - 256s - loss: 0.0940 - mse_loss: 0.0525 - loss_1: 4.1501 - val_loss: 0.0940 - val_mse_loss: 0.0528 - val_loss_1: 4.1224

Epoch 00018: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.
Epoch 19/100
 - 256s - loss: 0.0938 - mse_loss: 0.0525 - loss_1: 4.1361 - val_loss: 0.0939 - val_mse_loss: 0.0526 - val_loss_1: 4.1335
Epoch 20/100
 - 258s - loss: 0.0938 - mse_loss: 0.0524 - loss_1: 4.1437 - val_loss: 0.0939 - val_mse_loss: 0.0524 - val_loss_1: 4.1482
Epoch 21/100
 - 257s - loss: 0.0938 - mse_loss: 0.0524 - loss_1: 4.1450 - val_loss: 0.0938 - val_mse_loss: 0.0524 - val_loss_1: 4.1415

Epoch 00021: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.
Epoch 22/100
 - 257s - loss: 0.0938 - mse_loss: 0.0523 - loss_1: 4.1465 - val_loss: 0.0939 - val_mse_loss: 0.0524 - val_loss_1: 4.1462
Epoch 23/100
 - 256s - loss: 0.0938 - mse_loss: 0.0523 - loss_1: 4.1465 - val_loss: 0.0938 - val_mse_loss: 0.0524 - val_loss_1: 4.1448

Epoch 00023: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.
Epoch 24/100
 - 256s - loss: 0.0938 - mse_loss: 0.0523 - loss_1: 4.1460 - val_loss: 0.0939 - val_mse_loss: 0.0524 - val_loss_1: 4.1443
Epoch 25/100
 - 256s - loss: 0.0938 - mse_loss: 0.0523 - loss_1: 4.1459 - val_loss: 0.0939 - val_mse_loss: 0.0524 - val_loss_1: 4.1444

Epoch 00025: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.
Epoch 26/100
 - 257s - loss: 0.0938 - mse_loss: 0.0523 - loss_1: 4.1460 - val_loss: 0.0938 - val_mse_loss: 0.0524 - val_loss_1: 4.1444
Epoch 27/100
 - 256s - loss: 0.0938 - mse_loss: 0.0523 - loss_1: 4.1460 - val_loss: 0.0939 - val_mse_loss: 0.0524 - val_loss_1: 4.1445

Epoch 00027: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-09.
Epoch 28/100
 - 256s - loss: 0.0938 - mse_loss: 0.0523 - loss_1: 4.1461 - val_loss: 0.0938 - val_mse_loss: 0.0524 - val_loss_1: 4.1445
Epoch 29/100
 - 256s - loss: 0.0938 - mse_loss: 0.0523 - loss_1: 4.1461 - val_loss: 0.0939 - val_mse_loss: 0.0524 - val_loss_1: 4.1445

Epoch 00029: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-10.
Epoch 30/100
 - 258s - loss: 0.0938 - mse_loss: 0.0523 - loss_1: 4.1461 - val_loss: 0.0938 - val_mse_loss: 0.0524 - val_loss_1: 4.1445
Epoch 31/100
 - 258s - loss: 0.0938 - mse_loss: 0.0523 - loss_1: 4.1461 - val_loss: 0.0938 - val_mse_loss: 0.0524 - val_loss_1: 4.1445

Epoch 00031: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-11.
Epoch 32/100
 - 256s - loss: 0.0938 - mse_loss: 0.0523 - loss_1: 4.1461 - val_loss: 0.0938 - val_mse_loss: 0.0524 - val_loss_1: 4.1445
Epoch 33/100
 - 257s - loss: 0.0938 - mse_loss: 0.0523 - loss_1: 4.1461 - val_loss: 0.0938 - val_mse_loss: 0.0524 - val_loss_1: 4.1445

Epoch 00033: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-12.
Epoch 34/100
 - 258s - loss: 0.0938 - mse_loss: 0.0523 - loss_1: 4.1461 - val_loss: 0.0939 - val_mse_loss: 0.0524 - val_loss_1: 4.1445
Epoch 35/100
 - 256s - loss: 0.0938 - mse_loss: 0.0523 - loss_1: 4.1461 - val_loss: 0.0939 - val_mse_loss: 0.0524 - val_loss_1: 4.1445

Epoch 00035: ReduceLROnPlateau reducing learning rate to 1.0000001044244145e-13.
Epoch 36/100
 - 257s - loss: 0.0938 - mse_loss: 0.0523 - loss_1: 4.1461 - val_loss: 0.0939 - val_mse_loss: 0.0524 - val_loss_1: 4.1445
Epoch 37/100
 - 257s - loss: 0.0938 - mse_loss: 0.0523 - loss_1: 4.1461 - val_loss: 0.0939 - val_mse_loss: 0.0524 - val_loss_1: 4.1445

Epoch 00037: ReduceLROnPlateau reducing learning rate to 1.0000001179769417e-14.
Epoch 00037: early stopping
/eos/home-k/kiwoznia/dev/autoencoder_for_anomaly/convolutional_VAE/vae/vae_model.py:171: RuntimeWarning: divide by zero encountered in true_divide
  return np.random.exponential(1. / dist)  # numpy exponential dist takes 1/k param instead of k param
/afs/cern.ch/work/k/kiwoznia/.local/lib/python3.6/site-packages/matplotlib/colors.py:1211: RuntimeWarning: invalid value encountered in greater
  masked = np.abs(a) > (self.linthresh * self._linscale_adj)
Traceback (most recent call last):
  File "main.py", line 50, in <module>
    img_analysis.analyze( [reco_img_j1, reco_img_j2] )
  File "/eos/home-k/kiwoznia/dev/autoencoder_for_anomaly/convolutional_VAE/analysis_input/analysis_jet_image.py", line 47, in analyze
    self.plot_sampled_images( pixel_j1, 'j1')
  File "/eos/home-k/kiwoznia/dev/autoencoder_for_anomaly/convolutional_VAE/analysis_input/analysis_jet_image.py", line 120, in plot_sampled_images
    fig.colorbar(im, ax=ax)
  File "/afs/cern.ch/work/k/kiwoznia/.local/lib/python3.6/site-packages/matplotlib/figure.py", line 2215, in colorbar
    cb = cbar.colorbar_factory(cax, mappable, **cb_kw)
  File "/afs/cern.ch/work/k/kiwoznia/.local/lib/python3.6/site-packages/matplotlib/colorbar.py", line 1640, in colorbar_factory
    cb = Colorbar(cax, mappable, **kwargs)
  File "/afs/cern.ch/work/k/kiwoznia/.local/lib/python3.6/site-packages/matplotlib/colorbar.py", line 1183, in __init__
    ColorbarBase.__init__(self, ax, **kw)
  File "/afs/cern.ch/work/k/kiwoznia/.local/lib/python3.6/site-packages/matplotlib/colorbar.py", line 460, in __init__
    self.draw_all()
  File "/afs/cern.ch/work/k/kiwoznia/.local/lib/python3.6/site-packages/matplotlib/colorbar.py", line 493, in draw_all
    self._config_axes(X, Y)
  File "/afs/cern.ch/work/k/kiwoznia/.local/lib/python3.6/site-packages/matplotlib/colorbar.py", line 727, in _config_axes
    self.update_ticks()
  File "/afs/cern.ch/work/k/kiwoznia/.local/lib/python3.6/site-packages/matplotlib/colorbar.py", line 614, in update_ticks
    ticks, ticklabels, offset_string = self._ticker(locator, formatter)
  File "/afs/cern.ch/work/k/kiwoznia/.local/lib/python3.6/site-packages/matplotlib/colorbar.py", line 850, in _ticker
    b = np.array(locator())
  File "/afs/cern.ch/work/k/kiwoznia/.local/lib/python3.6/site-packages/matplotlib/ticker.py", line 2439, in __call__
    return self.tick_values(vmin, vmax)
  File "/afs/cern.ch/work/k/kiwoznia/.local/lib/python3.6/site-packages/matplotlib/ticker.py", line 2527, in tick_values
    decades.extend(b ** (np.arange(c_range[0], c_range[1], stride)))
ValueError: arange: cannot compute length
