setGPU: Setting GPU to: 0
2020-07-31 14:22:20.996686: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer.so.6'; dlerror: libnvinfer.so.6: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/afs/cern.ch/user/k/kiwoznia/.local/lib:/afs/cern.ch/user/k/kiwoznia/software/cuda/lib64:/usr/local/cuda-10.1/lib64
2020-07-31 14:22:20.997081: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer_plugin.so.6'; dlerror: libnvinfer_plugin.so.6: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/afs/cern.ch/user/k/kiwoznia/.local/lib:/afs/cern.ch/user/k/kiwoznia/software/cuda/lib64:/usr/local/cuda-10.1/lib64
2020-07-31 14:22:20.997097: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:30] Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
=== reading images from  /eos/user/k/kiwoznia/data/VAE_data/march_2020_data/input/images/54px/qcd_sqrtshatTeV_13TeV_PU40_SIDEBAND_mjj_cut_1.2M_pt_img_54px.h5  ===
read  1200000  jet 1 images and  1200000  jet 2 images
2020-07-31 14:26:17.761080: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2020-07-31 14:26:20.658046: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: 
pciBusID: 0000:04:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1
coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s
2020-07-31 14:26:20.660659: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-07-31 14:26:20.689134: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-07-31 14:26:20.703009: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-07-31 14:26:20.706610: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-07-31 14:26:20.727284: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-07-31 14:26:20.732534: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-07-31 14:26:20.740631: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-07-31 14:26:20.744252: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0
2020-07-31 14:26:20.744972: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-07-31 14:26:20.768112: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2200070000 Hz
2020-07-31 14:26:20.774420: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x170bb220 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-07-31 14:26:20.774477: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-07-31 14:26:20.926024: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1707d210 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2020-07-31 14:26:20.926068: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce GTX 1080 Ti, Compute Capability 6.1
2020-07-31 14:26:20.927843: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: 
pciBusID: 0000:04:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1
coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s
2020-07-31 14:26:20.927933: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-07-31 14:26:20.927967: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-07-31 14:26:20.927997: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-07-31 14:26:20.928035: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-07-31 14:26:20.928065: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-07-31 14:26:20.928094: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-07-31 14:26:20.928123: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-07-31 14:26:20.931143: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0
2020-07-31 14:26:20.931210: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-07-31 14:26:20.933883: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-07-31 14:26:20.933913: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0 
2020-07-31 14:26:20.933932: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N 
2020-07-31 14:26:20.937427: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10489 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:04:00.0, compute capability: 6.1)
Model: "encoder"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
encoder_input (InputLayer)      [(None, 54, 54)]     0                                            
__________________________________________________________________________________________________
lambda (Lambda)                 (None, 54, 54, 1)    0           encoder_input[0][0]              
__________________________________________________________________________________________________
conv2d (Conv2D)                 (None, 52, 52, 6)    60          lambda[0][0]                     
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 50, 50, 10)   550         conv2d[0][0]                     
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 48, 48, 14)   1274        conv2d_1[0][0]                   
__________________________________________________________________________________________________
average_pooling2d (AveragePooli (None, 24, 24, 14)   0           conv2d_2[0][0]                   
__________________________________________________________________________________________________
flatten (Flatten)               (None, 8064)         0           average_pooling2d[0][0]          
__________________________________________________________________________________________________
dense (Dense)                   (None, 474)          3822810     flatten[0][0]                    
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 192)          91200       dense[0][0]                      
__________________________________________________________________________________________________
z_mean (Dense)                  (None, 10)           1930        dense_1[0][0]                    
__________________________________________________________________________________________________
z_log_var (Dense)               (None, 10)           1930        dense_1[0][0]                    
__________________________________________________________________________________________________
sampling (Sampling)             (None, 10)           0           z_mean[0][0]                     
                                                                 z_log_var[0][0]                  
==================================================================================================
Total params: 3,919,754
Trainable params: 3,919,754
Non-trainable params: 0
__________________________________________________________________________________________________
Model: "decoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
z_sampling (InputLayer)      [(None, 10)]              0         
_________________________________________________________________
dense_2 (Dense)              (None, 192)               2112      
_________________________________________________________________
dense_3 (Dense)              (None, 474)               91482     
_________________________________________________________________
dense_4 (Dense)              (None, 8064)              3830400   
_________________________________________________________________
reshape (Reshape)            (None, 24, 24, 14)        0         
_________________________________________________________________
up_sampling2d (UpSampling2D) (None, 48, 48, 14)        0         
_________________________________________________________________
conv2d_transpose (Conv2DTran (None, 50, 50, 14)        1778      
_________________________________________________________________
conv2d_transpose_1 (Conv2DTr (None, 52, 52, 10)        1270      
_________________________________________________________________
conv2d_transpose_2 (Conv2DTr (None, 54, 54, 6)         546       
_________________________________________________________________
decoder_output (Conv2DTransp (None, 54, 54, 1)         55        
_________________________________________________________________
lambda_1 (Lambda)            (None, 54, 54)            0         
=================================================================
Total params: 3,927,643
Trainable params: 3,927,643
Non-trainable params: 0
_________________________________________________________________
Model: "vae"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
encoder_input (InputLayer)      [(None, 54, 54)]     0                                            
__________________________________________________________________________________________________
lambda (Lambda)                 (None, 54, 54, 1)    0           encoder_input[0][0]              
__________________________________________________________________________________________________
conv2d (Conv2D)                 (None, 52, 52, 6)    60          lambda[0][0]                     
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 50, 50, 10)   550         conv2d[0][0]                     
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 48, 48, 14)   1274        conv2d_1[0][0]                   
__________________________________________________________________________________________________
average_pooling2d (AveragePooli (None, 24, 24, 14)   0           conv2d_2[0][0]                   
__________________________________________________________________________________________________
flatten (Flatten)               (None, 8064)         0           average_pooling2d[0][0]          
__________________________________________________________________________________________________
dense (Dense)                   (None, 474)          3822810     flatten[0][0]                    
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 192)          91200       dense[0][0]                      
__________________________________________________________________________________________________
z_mean (Dense)                  (None, 10)           1930        dense_1[0][0]                    
__________________________________________________________________________________________________
z_log_var (Dense)               (None, 10)           1930        dense_1[0][0]                    
__________________________________________________________________________________________________
sampling (Sampling)             (None, 10)           0           z_mean[0][0]                     
                                                                 z_log_var[0][0]                  
__________________________________________________________________________________________________
decoder (Model)                 (None, 54, 54)       3927643     sampling[0][0]                   
==================================================================================================
Total params: 7,847,397
Trainable params: 7,847,397
Non-trainable params: 0
__________________________________________________________________________________________________
Train on 1800000 samples, validate on 600000 samples
Epoch 1/100
2020-07-31 14:26:23.801996: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-07-31 14:26:24.157128: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
1800000/1800000 - 281s - loss: 0.1312 - mse_loss: 0.1000 - loss_1: 3.1225 - val_loss: 0.1240 - val_mse_loss: 0.0893 - val_loss_1: 3.4671
Epoch 2/100
1800000/1800000 - 277s - loss: 0.1225 - mse_loss: 0.0881 - loss_1: 3.4371 - val_loss: 0.1215 - val_mse_loss: 0.0875 - val_loss_1: 3.3986
Epoch 3/100
1800000/1800000 - 275s - loss: 0.1208 - mse_loss: 0.0863 - loss_1: 3.4503 - val_loss: 0.1203 - val_mse_loss: 0.0852 - val_loss_1: 3.5191
Epoch 4/100
1800000/1800000 - 285s - loss: 0.1201 - mse_loss: 0.0854 - loss_1: 3.4648 - val_loss: 0.1194 - val_mse_loss: 0.0841 - val_loss_1: 3.5323
Epoch 5/100
1800000/1800000 - 289s - loss: 0.1197 - mse_loss: 0.0851 - loss_1: 3.4613 - val_loss: 0.1204 - val_mse_loss: 0.0883 - val_loss_1: 3.2078
Epoch 6/100

Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.
1800000/1800000 - 290s - loss: 0.1196 - mse_loss: 0.0853 - loss_1: 3.4337 - val_loss: 0.1195 - val_mse_loss: 0.0836 - val_loss_1: 3.5820
Epoch 7/100
1800000/1800000 - 290s - loss: 0.1180 - mse_loss: 0.0829 - loss_1: 3.5033 - val_loss: 0.1178 - val_mse_loss: 0.0828 - val_loss_1: 3.4949
Epoch 8/100
1800000/1800000 - 291s - loss: 0.1177 - mse_loss: 0.0828 - loss_1: 3.4919 - val_loss: 0.1177 - val_mse_loss: 0.0825 - val_loss_1: 3.5134
Epoch 9/100
1800000/1800000 - 291s - loss: 0.1176 - mse_loss: 0.0828 - loss_1: 3.4826 - val_loss: 0.1177 - val_mse_loss: 0.0837 - val_loss_1: 3.4001
Epoch 10/100
1800000/1800000 - 290s - loss: 0.1175 - mse_loss: 0.0830 - loss_1: 3.4550 - val_loss: 0.1176 - val_mse_loss: 0.0821 - val_loss_1: 3.5482
Epoch 11/100
1800000/1800000 - 291s - loss: 0.1175 - mse_loss: 0.0827 - loss_1: 3.4799 - val_loss: 0.1175 - val_mse_loss: 0.0830 - val_loss_1: 3.4442
Epoch 12/100
1800000/1800000 - 291s - loss: 0.1175 - mse_loss: 0.0831 - loss_1: 3.4422 - val_loss: 0.1175 - val_mse_loss: 0.0825 - val_loss_1: 3.4972
Epoch 13/100
1800000/1800000 - 289s - loss: 0.1174 - mse_loss: 0.0824 - loss_1: 3.5001 - val_loss: 0.1174 - val_mse_loss: 0.0827 - val_loss_1: 3.4729
Epoch 14/100

Epoch 00014: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.
1800000/1800000 - 291s - loss: 0.1174 - mse_loss: 0.0825 - loss_1: 3.4855 - val_loss: 0.1174 - val_mse_loss: 0.0820 - val_loss_1: 3.5395
Epoch 15/100
1800000/1800000 - 290s - loss: 0.1172 - mse_loss: 0.0820 - loss_1: 3.5216 - val_loss: 0.1172 - val_mse_loss: 0.0821 - val_loss_1: 3.5151
Epoch 16/100
1800000/1800000 - 291s - loss: 0.1172 - mse_loss: 0.0823 - loss_1: 3.4937 - val_loss: 0.1172 - val_mse_loss: 0.0824 - val_loss_1: 3.4871
Epoch 17/100

Epoch 00017: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.
1800000/1800000 - 291s - loss: 0.1172 - mse_loss: 0.0823 - loss_1: 3.4894 - val_loss: 0.1172 - val_mse_loss: 0.0823 - val_loss_1: 3.4984
Epoch 18/100
1800000/1800000 - 293s - loss: 0.1172 - mse_loss: 0.0822 - loss_1: 3.4958 - val_loss: 0.1172 - val_mse_loss: 0.0823 - val_loss_1: 3.4966
Epoch 19/100

Epoch 00019: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.
1800000/1800000 - 291s - loss: 0.1172 - mse_loss: 0.0822 - loss_1: 3.4951 - val_loss: 0.1172 - val_mse_loss: 0.0822 - val_loss_1: 3.4976
Epoch 20/100
1800000/1800000 - 291s - loss: 0.1172 - mse_loss: 0.0822 - loss_1: 3.4957 - val_loss: 0.1172 - val_mse_loss: 0.0822 - val_loss_1: 3.4976
Epoch 21/100

Epoch 00021: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.
1800000/1800000 - 290s - loss: 0.1172 - mse_loss: 0.0822 - loss_1: 3.4959 - val_loss: 0.1172 - val_mse_loss: 0.0822 - val_loss_1: 3.4977
Epoch 22/100
1800000/1800000 - 290s - loss: 0.1172 - mse_loss: 0.0822 - loss_1: 3.4959 - val_loss: 0.1172 - val_mse_loss: 0.0822 - val_loss_1: 3.4977
Epoch 23/100

Epoch 00023: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-09.
1800000/1800000 - 291s - loss: 0.1172 - mse_loss: 0.0822 - loss_1: 3.4960 - val_loss: 0.1172 - val_mse_loss: 0.0823 - val_loss_1: 3.4978
Epoch 24/100
1800000/1800000 - 287s - loss: 0.1172 - mse_loss: 0.0822 - loss_1: 3.4960 - val_loss: 0.1172 - val_mse_loss: 0.0822 - val_loss_1: 3.4978
Epoch 25/100

Epoch 00025: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-10.
1800000/1800000 - 290s - loss: 0.1172 - mse_loss: 0.0822 - loss_1: 3.4960 - val_loss: 0.1172 - val_mse_loss: 0.0822 - val_loss_1: 3.4978
Epoch 26/100
1800000/1800000 - 291s - loss: 0.1172 - mse_loss: 0.0822 - loss_1: 3.4960 - val_loss: 0.1172 - val_mse_loss: 0.0822 - val_loss_1: 3.4978
Epoch 27/100

Epoch 00027: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-11.
1800000/1800000 - 291s - loss: 0.1172 - mse_loss: 0.0822 - loss_1: 3.4960 - val_loss: 0.1172 - val_mse_loss: 0.0822 - val_loss_1: 3.4978
Epoch 28/100
1800000/1800000 - 291s - loss: 0.1172 - mse_loss: 0.0822 - loss_1: 3.4960 - val_loss: 0.1172 - val_mse_loss: 0.0822 - val_loss_1: 3.4978
Epoch 00028: early stopping
saving model to models/run_47
