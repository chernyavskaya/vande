setGPU: Setting GPU to: 0
2021-01-12 11:27:22.409362: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
tensorflow version:  2.3.1
2021-01-12 11:27:25.997583: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
2021-01-12 11:27:28.775874: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
pciBusID: 0000:18:00.0 name: Tesla T4 computeCapability: 7.5
coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s
2021-01-12 11:27:28.776014: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2021-01-12 11:27:28.894739: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2021-01-12 11:27:28.902661: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2021-01-12 11:27:28.905850: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2021-01-12 11:27:28.914780: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2021-01-12 11:27:28.918653: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2021-01-12 11:27:28.936772: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
2021-01-12 11:27:28.941403: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0
2021-01-12 11:27:28.945431: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-01-12 11:27:28.977841: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2200000000 Hz
2021-01-12 11:27:28.981883: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5cd07f0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2021-01-12 11:27:28.981922: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2021-01-12 11:27:29.129092: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5cd3480 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2021-01-12 11:27:29.129177: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5
2021-01-12 11:27:29.133028: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
pciBusID: 0000:18:00.0 name: Tesla T4 computeCapability: 7.5
coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s
2021-01-12 11:27:29.133119: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2021-01-12 11:27:29.133181: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2021-01-12 11:27:29.133225: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2021-01-12 11:27:29.133267: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2021-01-12 11:27:29.133308: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2021-01-12 11:27:29.133349: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2021-01-12 11:27:29.133390: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
2021-01-12 11:27:29.139410: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0
2021-01-12 11:27:29.139498: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2021-01-12 11:27:29.998999: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-01-12 11:27:29.999071: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0 
2021-01-12 11:27:29.999086: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N 
2021-01-12 11:27:30.002715: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 13970 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:18:00.0, compute capability: 7.5)
[DataReader] read_events_from_dir(): reading 1000000 events from /eos/user/k/kiwoznia/data/VAE_data/events/qcd_sqrtshatTeV_13TeV_PU40_NEW_EXT_sideband_parts

num files read in dir  /eos/user/k/kiwoznia/data/VAE_data/events/qcd_sqrtshatTeV_13TeV_PU40_NEW_EXT_sideband_parts :  2
[DataReader] read_events_from_dir(): reading 1000000 events from /eos/user/k/kiwoznia/data/VAE_data/events/qcd_sqrtshatTeV_13TeV_PU40_NEW_sideband_parts

num files read in dir  /eos/user/k/kiwoznia/data/VAE_data/events/qcd_sqrtshatTeV_13TeV_PU40_NEW_sideband_parts :  2
computed mean [-2.5694157e-04  3.9219353e-07  3.1619492e+00] and std-dev [ 0.23610476  0.23951028 14.948415  ]
Model: "encoder"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
encoder_input (InputLayer)      [(None, 100, 3)]     0                                            
__________________________________________________________________________________________________
lambda (Lambda)                 (None, 100, 3)       0           encoder_input[0][0]              
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 100, 3, 1)    0           lambda[0][0]                     
__________________________________________________________________________________________________
conv2d (Conv2D)                 (None, 98, 1, 6)     60          lambda_1[0][0]                   
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 98, 6)        0           conv2d[0][0]                     
__________________________________________________________________________________________________
conv1d (Conv1D)                 (None, 96, 10)       190         lambda_2[0][0]                   
__________________________________________________________________________________________________
conv1d_1 (Conv1D)               (None, 94, 14)       434         conv1d[0][0]                     
__________________________________________________________________________________________________
average_pooling1d (AveragePooli (None, 47, 14)       0           conv1d_1[0][0]                   
__________________________________________________________________________________________________
flatten (Flatten)               (None, 658)          0           average_pooling1d[0][0]          
__________________________________________________________________________________________________
dense (Dense)                   (None, 170)          112030      flatten[0][0]                    
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 40)           6840        dense[0][0]                      
__________________________________________________________________________________________________
z_mean (Dense)                  (None, 10)           410         dense_1[0][0]                    
__________________________________________________________________________________________________
z_log_var (Dense)               (None, 10)           410         dense_1[0][0]                    
__________________________________________________________________________________________________
sampling (Sampling)             (None, 10)           0           z_mean[0][0]                     
                                                                 z_log_var[0][0]                  
==================================================================================================
Total params: 120,374
Trainable params: 120,374
Non-trainable params: 0
__________________________________________________________________________________________________
Model: "decoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
z_sampling (InputLayer)      [(None, 10)]              0         
_________________________________________________________________
dense_2 (Dense)              (None, 40)                440       
_________________________________________________________________
dense_3 (Dense)              (None, 170)               6970      
_________________________________________________________________
dense_4 (Dense)              (None, 658)               112518    
_________________________________________________________________
reshape (Reshape)            (None, 47, 14)            0         
_________________________________________________________________
up_sampling1d (UpSampling1D) (None, 94, 14)            0         
_________________________________________________________________
conv1d_transpose (Conv1DTran (None, 96, 10)            430       
_________________________________________________________________
conv1d_transpose_1 (Conv1DTr (None, 98, 6)             186       
_________________________________________________________________
lambda_7 (Lambda)            (None, 98, 1, 6)          0         
_________________________________________________________________
conv_2d_transpose (Conv2DTra (None, 100, 3, 1)         55        
_________________________________________________________________
lambda_8 (Lambda)            (None, 100, 3)            0         
_________________________________________________________________
un_normalized_decoder_out (L (None, 100, 3)            0         
=================================================================
Total params: 120,599
Trainable params: 120,599
Non-trainable params: 0
_________________________________________________________________
Model: "vae"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
model_input (InputLayer)     [(None, 100, 3)]          0         
_________________________________________________________________
encoder (Functional)         [(None, 10), (None, 10),  120374    
_________________________________________________________________
decoder (Functional)         (None, 100, 3)            120599    
=================================================================
Total params: 240,973
Trainable params: 240,973
Non-trainable params: 0
_________________________________________________________________

### [12.1 11:38:37] Start of epoch 0
2021-01-12 11:39:08.048637: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2021-01-12 11:39:11.336173: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
Step 0: mean reco loss 227.0261, KL loss 0.0082 (in one batch)
Seen so far: 256 samples
Step 4000: mean reco loss 3.6432, KL loss 6.1356 (in one batch)
Seen so far: 1024256 samples
Step 8000: mean reco loss 1.0510, KL loss 6.7204 (in one batch)
Seen so far: 2048256 samples
Step 12000: mean reco loss 0.6204, KL loss 6.2099 (in one batch)
Seen so far: 3072256 samples
Step 16000: mean reco loss 0.6188, KL loss 5.7563 (in one batch)
Seen so far: 4096256 samples
Step 20000: mean reco loss 0.4773, KL loss 5.4546 (in one batch)
Seen so far: 5120256 samples
Step 24000: mean reco loss 0.6387, KL loss 5.7167 (in one batch)
Seen so far: 6144256 samples
Step 28000: mean reco loss 0.4626, KL loss 5.4411 (in one batch)
Seen so far: 7168256 samples
Step 32000: mean reco loss 0.4396, KL loss 5.1276 (in one batch)
Seen so far: 8192256 samples
Step 36000: mean reco loss 0.4527, KL loss 5.2489 (in one batch)
Seen so far: 9216256 samples
[DataGenerator]: __call__() yielded 10000000 samples
### [Epoch 0 - 11987.40 sec]: train loss reco 2.241 kl 5.749, val loss reco 0.404 kl 5.223 (mean / batch) ###

### [12.1 14:58:25] Start of epoch 1
Step 0: mean reco loss 0.4419, KL loss 5.1283 (in one batch)
Seen so far: 256 samples
Step 4000: mean reco loss 0.3910, KL loss 5.1349 (in one batch)
Seen so far: 1024256 samples
Step 8000: mean reco loss 0.3425, KL loss 5.1707 (in one batch)
Seen so far: 2048256 samples
Step 12000: mean reco loss 0.3214, KL loss 5.1487 (in one batch)
Seen so far: 3072256 samples
Step 16000: mean reco loss 0.3686, KL loss 5.2258 (in one batch)
Seen so far: 4096256 samples
Step 20000: mean reco loss 0.3779, KL loss 5.0198 (in one batch)
Seen so far: 5120256 samples
Step 24000: mean reco loss 0.3519, KL loss 5.1306 (in one batch)
Seen so far: 6144256 samples
Step 28000: mean reco loss 0.3460, KL loss 5.0797 (in one batch)
Seen so far: 7168256 samples
Step 32000: mean reco loss 0.3239, KL loss 5.0880 (in one batch)
Seen so far: 8192256 samples
Step 36000: mean reco loss 0.3472, KL loss 5.0524 (in one batch)
Seen so far: 9216256 samples
[DataGenerator]: __call__() yielded 10000000 samples
### [Epoch 1 - 12688.56 sec]: train loss reco 0.362 kl 5.152, val loss reco 0.313 kl 5.133 (mean / batch) ###

### [12.1 18:29:53] Start of epoch 2
Step 0: mean reco loss 0.2973, KL loss 5.0818 (in one batch)
Seen so far: 256 samples
Step 4000: mean reco loss 0.2648, KL loss 5.0669 (in one batch)
Seen so far: 1024256 samples
Step 8000: mean reco loss 0.3180, KL loss 5.1671 (in one batch)
Seen so far: 2048256 samples
Step 12000: mean reco loss 0.3164, KL loss 5.1700 (in one batch)
Seen so far: 3072256 samples
Step 16000: mean reco loss 0.2965, KL loss 5.1530 (in one batch)
Seen so far: 4096256 samples
Step 20000: mean reco loss 0.2831, KL loss 5.1240 (in one batch)
Seen so far: 5120256 samples
Step 24000: mean reco loss 0.2698, KL loss 5.0878 (in one batch)
Seen so far: 6144256 samples
Step 28000: mean reco loss 0.2801, KL loss 5.0646 (in one batch)
Seen so far: 7168256 samples
Step 32000: mean reco loss 0.3284, KL loss 5.1211 (in one batch)
Seen so far: 8192256 samples
Step 36000: mean reco loss 0.2564, KL loss 5.0607 (in one batch)
Seen so far: 9216256 samples
[DataGenerator]: __call__() yielded 10000000 samples
### [Epoch 2 - 14293.35 sec]: train loss reco 0.288 kl 5.093, val loss reco 0.243 kl 5.052 (mean / batch) ###

### [12.1 22:28:7] Start of epoch 3
Step 0: mean reco loss 0.2416, KL loss 5.0083 (in one batch)
Seen so far: 256 samples
Step 4000: mean reco loss 0.2737, KL loss 4.9874 (in one batch)
Seen so far: 1024256 samples
Step 8000: mean reco loss 0.2347, KL loss 5.0884 (in one batch)
Seen so far: 2048256 samples
Step 12000: mean reco loss 0.2145, KL loss 5.0607 (in one batch)
Seen so far: 3072256 samples
Step 16000: mean reco loss 0.2177, KL loss 5.1010 (in one batch)
Seen so far: 4096256 samples
Step 20000: mean reco loss 0.2600, KL loss 5.0753 (in one batch)
Seen so far: 5120256 samples
Step 24000: mean reco loss 0.2749, KL loss 5.0262 (in one batch)
Seen so far: 6144256 samples
Step 28000: mean reco loss 0.2130, KL loss 5.0020 (in one batch)
Seen so far: 7168256 samples
Step 32000: mean reco loss 0.2275, KL loss 5.0484 (in one batch)
Seen so far: 8192256 samples
Step 36000: mean reco loss 0.2193, KL loss 5.0836 (in one batch)
Seen so far: 9216256 samples
[DataGenerator]: __call__() yielded 10000000 samples
### [Epoch 3 - 8437.82 sec]: train loss reco 0.226 kl 5.050, val loss reco 0.226 kl 5.045 (mean / batch) ###

### [13.1 0:48:44] Start of epoch 4
Step 0: mean reco loss 0.2304, KL loss 5.0309 (in one batch)
Seen so far: 256 samples
Step 4000: mean reco loss 0.2103, KL loss 4.9983 (in one batch)
Seen so far: 1024256 samples
Step 8000: mean reco loss 0.2219, KL loss 4.9646 (in one batch)
Seen so far: 2048256 samples
Step 12000: mean reco loss 0.2201, KL loss 5.0066 (in one batch)
Seen so far: 3072256 samples
Step 16000: mean reco loss 0.2018, KL loss 4.9420 (in one batch)
Seen so far: 4096256 samples
Step 20000: mean reco loss 0.2180, KL loss 4.9226 (in one batch)
Seen so far: 5120256 samples
Step 24000: mean reco loss 0.2083, KL loss 4.9963 (in one batch)
Seen so far: 6144256 samples
Step 28000: mean reco loss 0.2074, KL loss 4.9257 (in one batch)
Seen so far: 7168256 samples
Step 32000: mean reco loss 0.2055, KL loss 4.9151 (in one batch)
Seen so far: 8192256 samples
Step 36000: mean reco loss 0.2029, KL loss 4.8795 (in one batch)
Seen so far: 9216256 samples
[DataGenerator]: __call__() yielded 10000000 samples
### [Epoch 4 - 8088.78 sec]: train loss reco 0.209 kl 4.957, val loss reco 0.203 kl 4.905 (mean / batch) ###
saving best so far model with valid loss 0.203 and kl loss 4.905
saving model to /eos/home-k/kiwoznia/data/VAE_models/run_108/best_so_far

### [13.1 3:3:34] Start of epoch 5
Step 0: mean reco loss 0.1975, KL loss 4.9357 (in one batch)
Seen so far: 256 samples
Step 4000: mean reco loss 0.2071, KL loss 4.8971 (in one batch)
Seen so far: 1024256 samples
Step 8000: mean reco loss 0.1933, KL loss 4.8492 (in one batch)
Seen so far: 2048256 samples
Step 12000: mean reco loss 0.1939, KL loss 4.8597 (in one batch)
Seen so far: 3072256 samples
Step 16000: mean reco loss 0.2061, KL loss 4.8506 (in one batch)
Seen so far: 4096256 samples
Step 20000: mean reco loss 0.2087, KL loss 4.8850 (in one batch)
Seen so far: 5120256 samples
Step 24000: mean reco loss 0.1892, KL loss 4.8362 (in one batch)
Seen so far: 6144256 samples
Step 28000: mean reco loss 0.2050, KL loss 4.8456 (in one batch)
Seen so far: 7168256 samples
Step 32000: mean reco loss 0.1942, KL loss 4.7999 (in one batch)
Seen so far: 8192256 samples
Step 36000: mean reco loss 0.1959, KL loss 4.7648 (in one batch)
Seen so far: 9216256 samples
[DataGenerator]: __call__() yielded 10000000 samples
### [Epoch 5 - 8394.02 sec]: train loss reco 0.203 kl 4.851, val loss reco 0.199 kl 4.809 (mean / batch) ###
saving best so far model with valid loss 0.199 and kl loss 4.809
saving model to /eos/home-k/kiwoznia/data/VAE_models/run_108/best_so_far

### [13.1 5:23:29] Start of epoch 6
Step 0: mean reco loss 0.1870, KL loss 4.8151 (in one batch)
Seen so far: 256 samples
Step 4000: mean reco loss 0.1905, KL loss 4.7185 (in one batch)
Seen so far: 1024256 samples
Step 8000: mean reco loss 0.1912, KL loss 4.7320 (in one batch)
Seen so far: 2048256 samples
Step 12000: mean reco loss 0.2209, KL loss 4.7797 (in one batch)
Seen so far: 3072256 samples
Step 16000: mean reco loss 0.2063, KL loss 4.7253 (in one batch)
Seen so far: 4096256 samples
Step 20000: mean reco loss 0.2061, KL loss 4.7192 (in one batch)
Seen so far: 5120256 samples
Step 24000: mean reco loss 0.1971, KL loss 4.7170 (in one batch)
Seen so far: 6144256 samples
Step 28000: mean reco loss 0.1961, KL loss 4.7064 (in one batch)
Seen so far: 7168256 samples
Step 32000: mean reco loss 0.1954, KL loss 4.7149 (in one batch)
Seen so far: 8192256 samples
Step 36000: mean reco loss 0.1844, KL loss 4.6788 (in one batch)
Seen so far: 9216256 samples
[DataGenerator]: __call__() yielded 10000000 samples
### [Epoch 6 - 7786.81 sec]: train loss reco 0.199 kl 4.734, val loss reco 0.194 kl 4.697 (mean / batch) ###
saving best so far model with valid loss 0.194 and kl loss 4.697
saving model to /eos/home-k/kiwoznia/data/VAE_models/run_108/best_so_far

### [13.1 7:33:16] Start of epoch 7
Step 0: mean reco loss 0.1946, KL loss 4.7290 (in one batch)
Seen so far: 256 samples
Step 4000: mean reco loss 0.2009, KL loss 4.6521 (in one batch)
Seen so far: 1024256 samples
Step 8000: mean reco loss 0.2139, KL loss 4.5691 (in one batch)
Seen so far: 2048256 samples
Step 12000: mean reco loss 0.1884, KL loss 4.6698 (in one batch)
Seen so far: 3072256 samples
Step 16000: mean reco loss 0.2009, KL loss 4.6725 (in one batch)
Seen so far: 4096256 samples
Step 20000: mean reco loss 0.1816, KL loss 4.6134 (in one batch)
Seen so far: 5120256 samples
Step 24000: mean reco loss 0.1923, KL loss 4.6245 (in one batch)
Seen so far: 6144256 samples
Step 28000: mean reco loss 0.1957, KL loss 4.6383 (in one batch)
Seen so far: 7168256 samples
Step 32000: mean reco loss 0.1817, KL loss 4.5890 (in one batch)
Seen so far: 8192256 samples
Step 36000: mean reco loss 0.1850, KL loss 4.5812 (in one batch)
Seen so far: 9216256 samples
[DataGenerator]: __call__() yielded 10000000 samples
### [Epoch 7 - 8039.16 sec]: train loss reco 0.195 kl 4.630, val loss reco 0.189 kl 4.578 (mean / batch) ###
saving best so far model with valid loss 0.189 and kl loss 4.578
saving model to /eos/home-k/kiwoznia/data/VAE_models/run_108/best_so_far

### [13.1 9:47:16] Start of epoch 8
Step 0: mean reco loss 0.1869, KL loss 4.5887 (in one batch)
Seen so far: 256 samples
Step 4000: mean reco loss 0.1898, KL loss 4.6306 (in one batch)
Seen so far: 1024256 samples
Step 8000: mean reco loss 0.1987, KL loss 4.5823 (in one batch)
Seen so far: 2048256 samples
Step 12000: mean reco loss 0.1951, KL loss 4.5638 (in one batch)
Seen so far: 3072256 samples
Step 16000: mean reco loss 0.1892, KL loss 4.5801 (in one batch)
Seen so far: 4096256 samples
Step 20000: mean reco loss 0.1812, KL loss 4.6005 (in one batch)
Seen so far: 5120256 samples
Step 24000: mean reco loss 0.1986, KL loss 4.6119 (in one batch)
Seen so far: 6144256 samples
Step 28000: mean reco loss 0.1859, KL loss 4.5303 (in one batch)
Seen so far: 7168256 samples
Step 32000: mean reco loss 0.1923, KL loss 4.5972 (in one batch)
Seen so far: 8192256 samples
Step 36000: mean reco loss 0.1736, KL loss 4.5602 (in one batch)
Seen so far: 9216256 samples
[DataGenerator]: __call__() yielded 10000000 samples
### [Epoch 8 - 8880.33 sec]: train loss reco 0.185 kl 4.571, val loss reco 0.178 kl 4.501 (mean / batch) ###
saving best so far model with valid loss 0.178 and kl loss 4.501
saving model to /eos/home-k/kiwoznia/data/VAE_models/run_108/best_so_far

### [13.1 12:15:18] Start of epoch 9
Step 0: mean reco loss 0.1674, KL loss 4.4732 (in one batch)
Seen so far: 256 samples
Step 4000: mean reco loss 0.1745, KL loss 4.5473 (in one batch)
Seen so far: 1024256 samples
Step 8000: mean reco loss 0.1755, KL loss 4.5432 (in one batch)
Seen so far: 2048256 samples
Step 12000: mean reco loss 0.1547, KL loss 4.5885 (in one batch)
Seen so far: 3072256 samples
Step 16000: mean reco loss 0.1617, KL loss 4.4871 (in one batch)
Seen so far: 4096256 samples
