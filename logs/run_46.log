setGPU: Setting GPU to: 0
/afs/cern.ch/work/k/kiwoznia/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/afs/cern.ch/work/k/kiwoznia/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/afs/cern.ch/work/k/kiwoznia/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/afs/cern.ch/work/k/kiwoznia/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/afs/cern.ch/work/k/kiwoznia/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/afs/cern.ch/work/k/kiwoznia/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
/afs/cern.ch/work/k/kiwoznia/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/afs/cern.ch/work/k/kiwoznia/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/afs/cern.ch/work/k/kiwoznia/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/afs/cern.ch/work/k/kiwoznia/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/afs/cern.ch/work/k/kiwoznia/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/afs/cern.ch/work/k/kiwoznia/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
=== reading images from  /eos/user/k/kiwoznia/data/VAE_data/march_2020_data/input/images/qcd_sqrtshatTeV_13TeV_PU40_SIDEBAND_mjj_cut_concat_1.2M_pt_img.h5  ===
read  1200714  jet 1 images and  1200714  jet 2 images
WARNING:tensorflow:From /afs/cern.ch/work/k/kiwoznia/.local/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
Model: "encoder"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
encoder_input (InputLayer)      [(None, 32, 32, 1)]  0                                            
__________________________________________________________________________________________________
conv2d (Conv2D)                 (None, 30, 30, 6)    60          encoder_input[0][0]              
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 28, 28, 10)   550         conv2d[0][0]                     
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 26, 26, 14)   1274        conv2d_1[0][0]                   
__________________________________________________________________________________________________
average_pooling2d (AveragePooli (None, 13, 13, 14)   0           conv2d_2[0][0]                   
__________________________________________________________________________________________________
flatten (Flatten)               (None, 2366)         0           average_pooling2d[0][0]          
__________________________________________________________________________________________________
dense (Dense)                   (None, 139)          329013      flatten[0][0]                    
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 56)           7840        dense[0][0]                      
__________________________________________________________________________________________________
z_mean (Dense)                  (None, 10)           570         dense_1[0][0]                    
__________________________________________________________________________________________________
z_log_var (Dense)               (None, 10)           570         dense_1[0][0]                    
__________________________________________________________________________________________________
z (Lambda)                      (None, 10)           0           z_mean[0][0]                     
                                                                 z_log_var[0][0]                  
==================================================================================================
Total params: 339,877
Trainable params: 339,877
Non-trainable params: 0
__________________________________________________________________________________________________
Model: "decoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
z_sampling (InputLayer)      [(None, 10)]              0         
_________________________________________________________________
dense_2 (Dense)              (None, 56)                616       
_________________________________________________________________
dense_3 (Dense)              (None, 139)               7923      
_________________________________________________________________
dense_4 (Dense)              (None, 2366)              331240    
_________________________________________________________________
reshape (Reshape)            (None, 13, 13, 14)        0         
_________________________________________________________________
up_sampling2d (UpSampling2D) (None, 26, 26, 14)        0         
_________________________________________________________________
conv2d_transpose (Conv2DTran (None, 28, 28, 14)        1778      
_________________________________________________________________
conv2d_transpose_1 (Conv2DTr (None, 30, 30, 10)        1270      
_________________________________________________________________
conv2d_transpose_2 (Conv2DTr (None, 32, 32, 6)         546       
_________________________________________________________________
decoder_output (Conv2DTransp (None, 32, 32, 1)         55        
=================================================================
Total params: 343,428
Trainable params: 343,428
Non-trainable params: 0
_________________________________________________________________
Model: "vae"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
encoder_input (InputLayer)   [(None, 32, 32, 1)]       0         
_________________________________________________________________
encoder (Model)              [(None, 10), (None, 10),  339877    
_________________________________________________________________
decoder (Model)              (None, 32, 32, 1)         343428    
=================================================================
Total params: 683,305
Trainable params: 683,305
Non-trainable params: 0
_________________________________________________________________
Train on 1801071 samples, validate on 600357 samples
2020-06-29 01:42:16.596984: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-06-29 01:42:16.642454: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2020-06-29 01:42:20.525040: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0xb7e3ef0 executing computations on platform CUDA. Devices:
2020-06-29 01:42:20.525117: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): GeForce GTX 1080 Ti, Compute Capability 6.1
2020-06-29 01:42:20.636160: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2200025000 Hz
2020-06-29 01:42:20.639950: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0xb578af0 executing computations on platform Host. Devices:
2020-06-29 01:42:20.640016: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2020-06-29 01:42:20.653672: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:04:00.0
2020-06-29 01:42:20.667321: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2020-06-29 01:42:20.770462: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2020-06-29 01:42:20.819907: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2020-06-29 01:42:20.842152: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2020-06-29 01:42:20.958563: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2020-06-29 01:42:21.031741: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2020-06-29 01:42:22.040960: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2020-06-29 01:42:22.050880: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2020-06-29 01:42:22.058299: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2020-06-29 01:42:22.061810: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-06-29 01:42:22.061850: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2020-06-29 01:42:22.061872: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2020-06-29 01:42:22.069899: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10481 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:04:00.0, compute capability: 6.1)
Epoch 1/100
2020-06-29 01:42:39.933496: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2020-06-29 01:42:41.060504: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
1801071/1801071 - 253s - loss: 0.1203 - mse_loss: 0.0911 - loss_1: 2.9156 - val_loss: 0.1078 - val_mse_loss: 0.0730 - val_loss_1: 3.4777
Epoch 2/100
1801071/1801071 - 238s - loss: 0.1051 - mse_loss: 0.0703 - loss_1: 3.4800 - val_loss: 0.1026 - val_mse_loss: 0.0669 - val_loss_1: 3.5639
Epoch 3/100
1801071/1801071 - 237s - loss: 0.1022 - mse_loss: 0.0658 - loss_1: 3.6304 - val_loss: 0.1007 - val_mse_loss: 0.0635 - val_loss_1: 3.7214
Epoch 4/100
1801071/1801071 - 229s - loss: 0.1005 - mse_loss: 0.0631 - loss_1: 3.7383 - val_loss: 0.0998 - val_mse_loss: 0.0627 - val_loss_1: 3.7189
Epoch 5/100
1801071/1801071 - 225s - loss: 0.0998 - mse_loss: 0.0619 - loss_1: 3.7820 - val_loss: 0.1006 - val_mse_loss: 0.0631 - val_loss_1: 3.7486
Epoch 6/100
1801071/1801071 - 221s - loss: 0.0993 - mse_loss: 0.0613 - loss_1: 3.7953 - val_loss: 0.0989 - val_mse_loss: 0.0611 - val_loss_1: 3.7856
Epoch 7/100
1801071/1801071 - 221s - loss: 0.0992 - mse_loss: 0.0611 - loss_1: 3.8075 - val_loss: 0.0985 - val_mse_loss: 0.0612 - val_loss_1: 3.7268
Epoch 8/100
1801071/1801071 - 221s - loss: 0.0989 - mse_loss: 0.0609 - loss_1: 3.8049 - val_loss: 0.0988 - val_mse_loss: 0.0604 - val_loss_1: 3.8474
Epoch 9/100

Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.
1801071/1801071 - 223s - loss: 0.0987 - mse_loss: 0.0605 - loss_1: 3.8179 - val_loss: 0.0988 - val_mse_loss: 0.0606 - val_loss_1: 3.8183
Epoch 10/100
1801071/1801071 - 220s - loss: 0.0972 - mse_loss: 0.0590 - loss_1: 3.8158 - val_loss: 0.0970 - val_mse_loss: 0.0587 - val_loss_1: 3.8262
Epoch 11/100
1801071/1801071 - 221s - loss: 0.0970 - mse_loss: 0.0589 - loss_1: 3.8119 - val_loss: 0.0969 - val_mse_loss: 0.0588 - val_loss_1: 3.8099
Epoch 12/100
1801071/1801071 - 223s - loss: 0.0969 - mse_loss: 0.0587 - loss_1: 3.8262 - val_loss: 0.0969 - val_mse_loss: 0.0586 - val_loss_1: 3.8289
Epoch 13/100
1801071/1801071 - 221s - loss: 0.0969 - mse_loss: 0.0586 - loss_1: 3.8283 - val_loss: 0.0969 - val_mse_loss: 0.0587 - val_loss_1: 3.8117
Epoch 14/100

Epoch 00014: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.
1801071/1801071 - 220s - loss: 0.0968 - mse_loss: 0.0586 - loss_1: 3.8215 - val_loss: 0.0968 - val_mse_loss: 0.0583 - val_loss_1: 3.8435
Epoch 15/100
1801071/1801071 - 221s - loss: 0.0967 - mse_loss: 0.0584 - loss_1: 3.8290 - val_loss: 0.0967 - val_mse_loss: 0.0584 - val_loss_1: 3.8266
Epoch 16/100
1801071/1801071 - 221s - loss: 0.0967 - mse_loss: 0.0584 - loss_1: 3.8276 - val_loss: 0.0966 - val_mse_loss: 0.0583 - val_loss_1: 3.8312
Epoch 17/100

Epoch 00017: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.
1801071/1801071 - 222s - loss: 0.0967 - mse_loss: 0.0584 - loss_1: 3.8313 - val_loss: 0.0966 - val_mse_loss: 0.0583 - val_loss_1: 3.8332
Epoch 18/100
1801071/1801071 - 221s - loss: 0.0967 - mse_loss: 0.0584 - loss_1: 3.8293 - val_loss: 0.0966 - val_mse_loss: 0.0584 - val_loss_1: 3.8281
Epoch 19/100

Epoch 00019: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.
1801071/1801071 - 222s - loss: 0.0967 - mse_loss: 0.0584 - loss_1: 3.8283 - val_loss: 0.0966 - val_mse_loss: 0.0583 - val_loss_1: 3.8309
Epoch 20/100
1801071/1801071 - 221s - loss: 0.0967 - mse_loss: 0.0583 - loss_1: 3.8304 - val_loss: 0.0966 - val_mse_loss: 0.0583 - val_loss_1: 3.8309
Epoch 21/100
1801071/1801071 - 221s - loss: 0.0966 - mse_loss: 0.0583 - loss_1: 3.8304 - val_loss: 0.0966 - val_mse_loss: 0.0583 - val_loss_1: 3.8311
Epoch 22/100

Epoch 00022: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.
1801071/1801071 - 224s - loss: 0.0967 - mse_loss: 0.0583 - loss_1: 3.8306 - val_loss: 0.0966 - val_mse_loss: 0.0583 - val_loss_1: 3.8312
Epoch 23/100
1801071/1801071 - 222s - loss: 0.0967 - mse_loss: 0.0583 - loss_1: 3.8308 - val_loss: 0.0967 - val_mse_loss: 0.0583 - val_loss_1: 3.8313
Epoch 24/100

Epoch 00024: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-09.
1801071/1801071 - 222s - loss: 0.0967 - mse_loss: 0.0584 - loss_1: 3.8308 - val_loss: 0.0966 - val_mse_loss: 0.0583 - val_loss_1: 3.8313
Epoch 25/100
1801071/1801071 - 221s - loss: 0.0967 - mse_loss: 0.0584 - loss_1: 3.8309 - val_loss: 0.0966 - val_mse_loss: 0.0583 - val_loss_1: 3.8313
Epoch 26/100

Epoch 00026: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-10.
1801071/1801071 - 220s - loss: 0.0966 - mse_loss: 0.0583 - loss_1: 3.8309 - val_loss: 0.0966 - val_mse_loss: 0.0583 - val_loss_1: 3.8313
Epoch 27/100
1801071/1801071 - 222s - loss: 0.0967 - mse_loss: 0.0584 - loss_1: 3.8308 - val_loss: 0.0966 - val_mse_loss: 0.0583 - val_loss_1: 3.8313
Epoch 00027: early stopping
saving model to models/run_46
