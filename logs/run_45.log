/afs/cern.ch/work/k/kiwoznia/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/afs/cern.ch/work/k/kiwoznia/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/afs/cern.ch/work/k/kiwoznia/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/afs/cern.ch/work/k/kiwoznia/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/afs/cern.ch/work/k/kiwoznia/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/afs/cern.ch/work/k/kiwoznia/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
/afs/cern.ch/work/k/kiwoznia/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/afs/cern.ch/work/k/kiwoznia/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/afs/cern.ch/work/k/kiwoznia/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/afs/cern.ch/work/k/kiwoznia/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/afs/cern.ch/work/k/kiwoznia/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/afs/cern.ch/work/k/kiwoznia/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
WARNING:tensorflow:From /afs/cern.ch/work/k/kiwoznia/.local/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
Model: "encoder"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
encoder_input (InputLayer)      [(None, 100, 3)]     0                                            
__________________________________________________________________________________________________
lambda (Lambda)                 (None, 100, 3, 1)    0           encoder_input[0][0]              
__________________________________________________________________________________________________
conv2d (Conv2D)                 (None, 98, 1, 6)     60          lambda[0][0]                     
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 98, 6)        0           conv2d[0][0]                     
__________________________________________________________________________________________________
conv1d (Conv1D)                 (None, 96, 10)       190         lambda_1[0][0]                   
__________________________________________________________________________________________________
conv1d_1 (Conv1D)               (None, 94, 14)       434         conv1d[0][0]                     
__________________________________________________________________________________________________
average_pooling1d (AveragePooli (None, 47, 14)       0           conv1d_1[0][0]                   
__________________________________________________________________________________________________
flatten (Flatten)               (None, 658)          0           average_pooling1d[0][0]          
__________________________________________________________________________________________________
dense (Dense)                   (None, 38)           25042       flatten[0][0]                    
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 15)           585         dense[0][0]                      
__________________________________________________________________________________________________
z_mean (Dense)                  (None, 10)           160         dense_1[0][0]                    
__________________________________________________________________________________________________
z_log_var (Dense)               (None, 10)           160         dense_1[0][0]                    
__________________________________________________________________________________________________
z (Lambda)                      (None, 10)           0           z_mean[0][0]                     
                                                                 z_log_var[0][0]                  
==================================================================================================
Total params: 26,631
Trainable params: 26,631
Non-trainable params: 0
__________________________________________________________________________________________________
WARNING:tensorflow:Entity <bound method Conv1DTranspose.call of <vae.vae_3Dloss_model.Conv1DTranspose object at 0x7f0c391047f0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv1DTranspose.call of <vae.vae_3Dloss_model.Conv1DTranspose object at 0x7f0c391047f0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method Conv1DTranspose.call of <vae.vae_3Dloss_model.Conv1DTranspose object at 0x7f0c39019320>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv1DTranspose.call of <vae.vae_3Dloss_model.Conv1DTranspose object at 0x7f0c39019320>>: AssertionError: Bad argument number for Name: 3, expecting 4
Model: "decoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
z_sampling (InputLayer)      [(None, 10)]              0         
_________________________________________________________________
dense_2 (Dense)              (None, 15)                165       
_________________________________________________________________
dense_3 (Dense)              (None, 38)                608       
_________________________________________________________________
dense_4 (Dense)              (None, 658)               25662     
_________________________________________________________________
reshape (Reshape)            (None, 47, 14)            0         
_________________________________________________________________
up_sampling1d (UpSampling1D) (None, 94, 14)            0         
_________________________________________________________________
conv1d_transpose (Conv1DTran (None, 96, 10)            430       
_________________________________________________________________
conv1d_transpose_1 (Conv1DTr (None, 98, 6)             186       
_________________________________________________________________
lambda_6 (Lambda)            (None, 98, 1, 6)          0         
_________________________________________________________________
conv_2d_transpose (Conv2DTra (None, 100, 3, 1)         55        
_________________________________________________________________
decoder_output (Lambda)      (None, 100, 3)            0         
=================================================================
Total params: 27,106
Trainable params: 27,106
Non-trainable params: 0
_________________________________________________________________
WARNING:tensorflow:Entity <bound method Conv1DTranspose.call of <vae.vae_3Dloss_model.Conv1DTranspose object at 0x7f0c391047f0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv1DTranspose.call of <vae.vae_3Dloss_model.Conv1DTranspose object at 0x7f0c391047f0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method Conv1DTranspose.call of <vae.vae_3Dloss_model.Conv1DTranspose object at 0x7f0c39019320>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv1DTranspose.call of <vae.vae_3Dloss_model.Conv1DTranspose object at 0x7f0c39019320>>: AssertionError: Bad argument number for Name: 3, expecting 4
Model: "vae"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
encoder_input (InputLayer)   [(None, 100, 3)]          0         
_________________________________________________________________
encoder (Model)              [(None, 10), (None, 10),  26631     
_________________________________________________________________
decoder (Model)              (None, 100, 3)            27106     
=================================================================
Total params: 53,737
Trainable params: 53,737
Non-trainable params: 0
_________________________________________________________________
WARNING:tensorflow:From /eos/home-k/kiwoznia/dev/autoencoder_for_anomaly/convolutional_VAE/vae/losses.py:72: The name tf.squared_difference is deprecated. Please use tf.math.squared_difference instead.

Train on 1801071 samples, validate on 600357 samples
2020-06-18 16:13:43.712876: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-06-18 16:13:43.727354: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2020-06-18 16:13:50.147387: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0xb843fe0 executing computations on platform CUDA. Devices:
2020-06-18 16:13:50.147440: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): GeForce GTX 1080 Ti, Compute Capability 6.1
2020-06-18 16:13:50.147452: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (1): GeForce GTX 1080 Ti, Compute Capability 6.1
2020-06-18 16:13:50.147461: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (2): GeForce GTX 1080 Ti, Compute Capability 6.1
2020-06-18 16:13:50.147468: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (3): GeForce GTX 1080 Ti, Compute Capability 6.1
2020-06-18 16:13:50.147476: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (4): GeForce GTX 1080 Ti, Compute Capability 6.1
2020-06-18 16:13:50.147483: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (5): GeForce GTX 1080 Ti, Compute Capability 6.1
2020-06-18 16:13:50.147490: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (6): GeForce GTX 1080 Ti, Compute Capability 6.1
2020-06-18 16:13:50.147497: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (7): GeForce GTX 1080 Ti, Compute Capability 6.1
2020-06-18 16:13:50.155423: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2199885000 Hz
2020-06-18 16:13:50.163440: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0xb674380 executing computations on platform Host. Devices:
2020-06-18 16:13:50.163485: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2020-06-18 16:13:50.187046: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:04:00.0
2020-06-18 16:13:50.188673: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 1 with properties: 
name: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:05:00.0
2020-06-18 16:13:50.190278: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 2 with properties: 
name: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:08:00.0
2020-06-18 16:13:50.191855: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 3 with properties: 
name: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:09:00.0
2020-06-18 16:13:50.196749: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 4 with properties: 
name: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:83:00.0
2020-06-18 16:13:50.198343: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 5 with properties: 
name: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:84:00.0
2020-06-18 16:13:50.199906: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 6 with properties: 
name: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:87:00.0
2020-06-18 16:13:50.200986: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 7 with properties: 
name: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:88:00.0
2020-06-18 16:13:50.202631: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2020-06-18 16:13:50.221092: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2020-06-18 16:13:50.229204: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2020-06-18 16:13:50.231960: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2020-06-18 16:13:50.247749: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2020-06-18 16:13:50.258121: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2020-06-18 16:13:50.263514: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2020-06-18 16:13:50.290320: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0, 1, 2, 3, 4, 5, 6, 7
2020-06-18 16:13:50.290371: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2020-06-18 16:13:50.309522: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-06-18 16:13:50.309550: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 1 2 3 4 5 6 7 
2020-06-18 16:13:50.309566: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N Y Y Y N N N N 
2020-06-18 16:13:50.309575: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 1:   Y N Y Y N N N N 
2020-06-18 16:13:50.309582: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 2:   Y Y N Y N N N N 
2020-06-18 16:13:50.309590: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 3:   Y Y Y N N N N N 
2020-06-18 16:13:50.309597: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 4:   N N N N N Y Y Y 
2020-06-18 16:13:50.309605: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 5:   N N N N Y N Y Y 
2020-06-18 16:13:50.309613: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 6:   N N N N Y Y N Y 
2020-06-18 16:13:50.309620: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 7:   N N N N Y Y Y N 
2020-06-18 16:13:50.323257: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10479 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:04:00.0, compute capability: 6.1)
2020-06-18 16:13:50.325184: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 10479 MB memory) -> physical GPU (device: 1, name: GeForce GTX 1080 Ti, pci bus id: 0000:05:00.0, compute capability: 6.1)
2020-06-18 16:13:50.327055: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:2 with 10479 MB memory) -> physical GPU (device: 2, name: GeForce GTX 1080 Ti, pci bus id: 0000:08:00.0, compute capability: 6.1)
2020-06-18 16:13:50.328913: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:3 with 10479 MB memory) -> physical GPU (device: 3, name: GeForce GTX 1080 Ti, pci bus id: 0000:09:00.0, compute capability: 6.1)
2020-06-18 16:13:50.330735: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:4 with 10479 MB memory) -> physical GPU (device: 4, name: GeForce GTX 1080 Ti, pci bus id: 0000:83:00.0, compute capability: 6.1)
2020-06-18 16:13:50.333022: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:5 with 10479 MB memory) -> physical GPU (device: 5, name: GeForce GTX 1080 Ti, pci bus id: 0000:84:00.0, compute capability: 6.1)
2020-06-18 16:13:50.334857: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:6 with 10479 MB memory) -> physical GPU (device: 6, name: GeForce GTX 1080 Ti, pci bus id: 0000:87:00.0, compute capability: 6.1)
2020-06-18 16:13:50.343838: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:7 with 130 MB memory) -> physical GPU (device: 7, name: GeForce GTX 1080 Ti, pci bus id: 0000:88:00.0, compute capability: 6.1)
Epoch 1/100
2020-06-18 16:13:52.591756: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2020-06-18 16:13:52.897073: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
1801071/1801071 - 240s - loss: 4309.1134 - threeD_loss: 4228.9194 - loss_1: 8020.6763 - val_loss: 528.1182 - val_threeD_loss: 525.1566 - val_loss_1: 296.1468
Epoch 2/100
1801071/1801071 - 239s - loss: 440.5552 - threeD_loss: 438.6438 - loss_1: 191.1971 - val_loss: 271.4858 - val_threeD_loss: 270.0406 - val_loss_1: 144.5374
Epoch 3/100
1801071/1801071 - 240s - loss: 310.9168 - threeD_loss: 309.5551 - loss_1: 136.1706 - val_loss: 143.5173 - val_threeD_loss: 142.1910 - val_loss_1: 132.6264
Epoch 4/100
1801071/1801071 - 241s - loss: 92.5839 - threeD_loss: 91.2932 - loss_1: 129.0936 - val_loss: 89.8862 - val_threeD_loss: 88.6245 - val_loss_1: 126.1538
Epoch 5/100
1801071/1801071 - 238s - loss: 79.9847 - threeD_loss: 78.8103 - loss_1: 117.4348 - val_loss: 80.8999 - val_threeD_loss: 79.7766 - val_loss_1: 112.3412
Epoch 6/100
1801071/1801071 - 239s - loss: 73.2087 - threeD_loss: 72.0491 - loss_1: 115.9775 - val_loss: 62.5475 - val_threeD_loss: 61.3664 - val_loss_1: 118.1116
Epoch 7/100
1801071/1801071 - 240s - loss: 63.5980 - threeD_loss: 62.4300 - loss_1: 116.7755 - val_loss: 56.4475 - val_threeD_loss: 55.3018 - val_loss_1: 114.5664
Epoch 8/100
1801071/1801071 - 239s - loss: 58.3422 - threeD_loss: 57.2105 - loss_1: 113.1724 - val_loss: 51.5513 - val_threeD_loss: 50.4266 - val_loss_1: 112.4690
Epoch 9/100
1801071/1801071 - 244s - loss: 54.0486 - threeD_loss: 52.9594 - loss_1: 108.9245 - val_loss: 47.6777 - val_threeD_loss: 46.5999 - val_loss_1: 107.7692
Epoch 10/100
1801071/1801071 - 242s - loss: 44.8537 - threeD_loss: 43.7846 - loss_1: 106.9174 - val_loss: 35.5290 - val_threeD_loss: 34.4697 - val_loss_1: 105.9387
Epoch 11/100
1801071/1801071 - 239s - loss: 37.4022 - threeD_loss: 36.3785 - loss_1: 102.3725 - val_loss: 33.8222 - val_threeD_loss: 32.8256 - val_loss_1: 99.6577
Epoch 12/100
1801071/1801071 - 238s - loss: 35.9900 - threeD_loss: 35.0068 - loss_1: 98.3265 - val_loss: 31.5566 - val_threeD_loss: 30.5842 - val_loss_1: 97.2374
Epoch 13/100
1801071/1801071 - 240s - loss: 33.2831 - threeD_loss: 32.3222 - loss_1: 96.0938 - val_loss: 30.2739 - val_threeD_loss: 29.3379 - val_loss_1: 93.5985
Epoch 14/100
1801071/1801071 - 239s - loss: 31.6870 - threeD_loss: 30.7655 - loss_1: 92.1344 - val_loss: 29.2972 - val_threeD_loss: 28.3890 - val_loss_1: 90.8206
Epoch 15/100
1801071/1801071 - 235s - loss: 31.2151 - threeD_loss: 30.3198 - loss_1: 89.5259 - val_loss: 30.0540 - val_threeD_loss: 29.1705 - val_loss_1: 88.3474
Epoch 16/100
1801071/1801071 - 234s - loss: 30.4313 - threeD_loss: 29.5552 - loss_1: 87.6079 - val_loss: 27.5976 - val_threeD_loss: 26.7302 - val_loss_1: 86.7508
Epoch 17/100
1801071/1801071 - 236s - loss: 28.6493 - threeD_loss: 27.7954 - loss_1: 85.3909 - val_loss: 26.2154 - val_threeD_loss: 25.3702 - val_loss_1: 84.5177
Epoch 18/100
1801071/1801071 - 239s - loss: 28.3079 - threeD_loss: 27.4726 - loss_1: 83.5316 - val_loss: 25.7528 - val_threeD_loss: 24.9260 - val_loss_1: 82.6842
Epoch 19/100
1801071/1801071 - 238s - loss: 28.2522 - threeD_loss: 27.4267 - loss_1: 82.5546 - val_loss: 28.0075 - val_threeD_loss: 27.1818 - val_loss_1: 82.5675
Epoch 20/100

Epoch 00020: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.
1801071/1801071 - 243s - loss: 28.2659 - threeD_loss: 27.4469 - loss_1: 81.8919 - val_loss: 28.5081 - val_threeD_loss: 27.6983 - val_loss_1: 80.9847
Epoch 21/100
1801071/1801071 - 241s - loss: 24.6264 - threeD_loss: 23.8214 - loss_1: 80.5171 - val_loss: 24.4515 - val_threeD_loss: 23.6548 - val_loss_1: 79.6744
Epoch 22/100
1801071/1801071 - 236s - loss: 24.4701 - threeD_loss: 23.6824 - loss_1: 78.7805 - val_loss: 24.4216 - val_threeD_loss: 23.6414 - val_loss_1: 78.0203
Epoch 23/100
1801071/1801071 - 236s - loss: 24.3267 - threeD_loss: 23.5537 - loss_1: 77.3004 - val_loss: 24.2326 - val_threeD_loss: 23.4662 - val_loss_1: 76.6388
Epoch 24/100
1801071/1801071 - 234s - loss: 24.1940 - threeD_loss: 23.4336 - loss_1: 76.0481 - val_loss: 23.9919 - val_threeD_loss: 23.2353 - val_loss_1: 75.6600
Epoch 25/100
1801071/1801071 - 234s - loss: 24.0370 - threeD_loss: 23.2861 - loss_1: 75.0860 - val_loss: 23.8555 - val_threeD_loss: 23.1084 - val_loss_1: 74.7076
Epoch 26/100
1801071/1801071 - 234s - loss: 23.8249 - threeD_loss: 23.0822 - loss_1: 74.2717 - val_loss: 23.5516 - val_threeD_loss: 22.8116 - val_loss_1: 74.0028
Epoch 27/100
1801071/1801071 - 234s - loss: 23.3889 - threeD_loss: 22.6520 - loss_1: 73.7024 - val_loss: 22.9179 - val_threeD_loss: 22.1829 - val_loss_1: 73.5049
Epoch 28/100
1801071/1801071 - 235s - loss: 22.6167 - threeD_loss: 21.8818 - loss_1: 73.4909 - val_loss: 22.1251 - val_threeD_loss: 21.3896 - val_loss_1: 73.5421
Epoch 29/100
1801071/1801071 - 234s - loss: 22.0046 - threeD_loss: 21.2696 - loss_1: 73.4938 - val_loss: 21.7225 - val_threeD_loss: 20.9873 - val_loss_1: 73.5167
Epoch 30/100
1801071/1801071 - 238s - loss: 21.6672 - threeD_loss: 20.9342 - loss_1: 73.2843 - val_loss: 21.3992 - val_threeD_loss: 20.6684 - val_loss_1: 73.0902
Epoch 31/100
1801071/1801071 - 238s - loss: 21.3608 - threeD_loss: 20.6307 - loss_1: 73.0033 - val_loss: 21.0799 - val_threeD_loss: 20.3492 - val_loss_1: 73.0768
Epoch 32/100
1801071/1801071 - 234s - loss: 21.1095 - threeD_loss: 20.3813 - loss_1: 72.8241 - val_loss: 20.9142 - val_threeD_loss: 20.1863 - val_loss_1: 72.7856
Epoch 33/100
1801071/1801071 - 237s - loss: 20.9285 - threeD_loss: 20.2023 - loss_1: 72.6164 - val_loss: 20.8705 - val_threeD_loss: 20.1451 - val_loss_1: 72.5416
Epoch 34/100
1801071/1801071 - 234s - loss: 20.7945 - threeD_loss: 20.0698 - loss_1: 72.4769 - val_loss: 20.7971 - val_threeD_loss: 20.0718 - val_loss_1: 72.5317
Epoch 35/100
1801071/1801071 - 233s - loss: 20.3548 - threeD_loss: 19.6317 - loss_1: 72.3080 - val_loss: 20.1707 - val_threeD_loss: 19.4497 - val_loss_1: 72.0985
Epoch 36/100
1801071/1801071 - 235s - loss: 20.1345 - threeD_loss: 19.4159 - loss_1: 71.8673 - val_loss: 20.0404 - val_threeD_loss: 19.3238 - val_loss_1: 71.6658
Epoch 37/100
1801071/1801071 - 238s - loss: 20.0584 - threeD_loss: 19.3438 - loss_1: 71.4571 - val_loss: 19.9846 - val_threeD_loss: 19.2715 - val_loss_1: 71.3113
Epoch 38/100
1801071/1801071 - 237s - loss: 20.0037 - threeD_loss: 19.2926 - loss_1: 71.1035 - val_loss: 19.9024 - val_threeD_loss: 19.1929 - val_loss_1: 70.9512
Epoch 39/100
1801071/1801071 - 236s - loss: 19.9687 - threeD_loss: 19.2609 - loss_1: 70.7832 - val_loss: 19.8724 - val_threeD_loss: 19.1659 - val_loss_1: 70.6509
Epoch 40/100
1801071/1801071 - 231s - loss: 19.9395 - threeD_loss: 19.2349 - loss_1: 70.4653 - val_loss: 20.0161 - val_threeD_loss: 19.3121 - val_loss_1: 70.3956
Epoch 41/100

Epoch 00041: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.
1801071/1801071 - 232s - loss: 19.9193 - threeD_loss: 19.2172 - loss_1: 70.2148 - val_loss: 19.8760 - val_threeD_loss: 19.1745 - val_loss_1: 70.1531
Epoch 42/100
1801071/1801071 - 233s - loss: 19.7941 - threeD_loss: 19.0930 - loss_1: 70.1091 - val_loss: 19.7607 - val_threeD_loss: 19.0596 - val_loss_1: 70.1112
Epoch 43/100
1801071/1801071 - 234s - loss: 19.7903 - threeD_loss: 19.0897 - loss_1: 70.0552 - val_loss: 19.7558 - val_threeD_loss: 19.0553 - val_loss_1: 70.0582
Epoch 44/100
1801071/1801071 - 232s - loss: 19.7878 - threeD_loss: 19.0877 - loss_1: 70.0142 - val_loss: 19.7472 - val_threeD_loss: 19.0471 - val_loss_1: 70.0147
Epoch 45/100
1801071/1801071 - 232s - loss: 19.7845 - threeD_loss: 19.0850 - loss_1: 69.9553 - val_loss: 19.7555 - val_threeD_loss: 19.0560 - val_loss_1: 69.9581
Epoch 46/100
1801071/1801071 - 230s - loss: 19.7816 - threeD_loss: 19.0826 - loss_1: 69.8997 - val_loss: 19.7428 - val_threeD_loss: 19.0437 - val_loss_1: 69.9124
Epoch 47/100
1801071/1801071 - 233s - loss: 19.7789 - threeD_loss: 19.0804 - loss_1: 69.8486 - val_loss: 19.7464 - val_threeD_loss: 19.0478 - val_loss_1: 69.8607
Epoch 48/100
1801071/1801071 - 232s - loss: 19.7759 - threeD_loss: 19.0779 - loss_1: 69.8042 - val_loss: 19.7355 - val_threeD_loss: 19.0374 - val_loss_1: 69.8129
Epoch 49/100
1801071/1801071 - 231s - loss: 19.7737 - threeD_loss: 19.0761 - loss_1: 69.7551 - val_loss: 19.7355 - val_threeD_loss: 19.0380 - val_loss_1: 69.7532
Epoch 50/100

Epoch 00050: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.
1801071/1801071 - 233s - loss: 19.7706 - threeD_loss: 19.0735 - loss_1: 69.7035 - val_loss: 19.7356 - val_threeD_loss: 19.0385 - val_loss_1: 69.7160
Epoch 51/100
1801071/1801071 - 234s - loss: 19.7550 - threeD_loss: 19.0582 - loss_1: 69.6801 - val_loss: 19.7215 - val_threeD_loss: 19.0244 - val_loss_1: 69.7080
Epoch 52/100
1801071/1801071 - 233s - loss: 19.7547 - threeD_loss: 19.0579 - loss_1: 69.6717 - val_loss: 19.7214 - val_threeD_loss: 19.0244 - val_loss_1: 69.7020
Epoch 53/100
1801071/1801071 - 232s - loss: 19.7541 - threeD_loss: 19.0575 - loss_1: 69.6667 - val_loss: 19.7208 - val_threeD_loss: 19.0238 - val_loss_1: 69.6971
Epoch 54/100
1801071/1801071 - 231s - loss: 19.7537 - threeD_loss: 19.0571 - loss_1: 69.6615 - val_loss: 19.7204 - val_threeD_loss: 19.0235 - val_loss_1: 69.6874
Epoch 55/100
1801071/1801071 - 239s - loss: 19.7534 - threeD_loss: 19.0569 - loss_1: 69.6513 - val_loss: 19.7207 - val_threeD_loss: 19.0240 - val_loss_1: 69.6770
Epoch 56/100
1801071/1801071 - 235s - loss: 19.7533 - threeD_loss: 19.0569 - loss_1: 69.6453 - val_loss: 19.7201 - val_threeD_loss: 19.0234 - val_loss_1: 69.6724
Epoch 57/100
1801071/1801071 - 236s - loss: 19.7526 - threeD_loss: 19.0562 - loss_1: 69.6354 - val_loss: 19.7202 - val_threeD_loss: 19.0235 - val_loss_1: 69.6612
Epoch 58/100
1801071/1801071 - 235s - loss: 19.7526 - threeD_loss: 19.0563 - loss_1: 69.6276 - val_loss: 19.7194 - val_threeD_loss: 19.0228 - val_loss_1: 69.6593
Epoch 59/100
1801071/1801071 - 236s - loss: 19.7525 - threeD_loss: 19.0562 - loss_1: 69.6295 - val_loss: 19.7195 - val_threeD_loss: 19.0229 - val_loss_1: 69.6620
Epoch 60/100

Epoch 00060: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.
1801071/1801071 - 235s - loss: 19.7520 - threeD_loss: 19.0558 - loss_1: 69.6247 - val_loss: 19.7221 - val_threeD_loss: 19.0255 - val_loss_1: 69.6522
Epoch 61/100
1801071/1801071 - 236s - loss: 19.7500 - threeD_loss: 19.0537 - loss_1: 69.6203 - val_loss: 19.7178 - val_threeD_loss: 19.0213 - val_loss_1: 69.6517
Epoch 62/100
1801071/1801071 - 235s - loss: 19.7499 - threeD_loss: 19.0536 - loss_1: 69.6195 - val_loss: 19.7174 - val_threeD_loss: 19.0209 - val_loss_1: 69.6507
Epoch 63/100
1801071/1801071 - 235s - loss: 19.7498 - threeD_loss: 19.0536 - loss_1: 69.6182 - val_loss: 19.7178 - val_threeD_loss: 19.0213 - val_loss_1: 69.6496
Epoch 64/100

Epoch 00064: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.
1801071/1801071 - 234s - loss: 19.7498 - threeD_loss: 19.0537 - loss_1: 69.6172 - val_loss: 19.7177 - val_threeD_loss: 19.0212 - val_loss_1: 69.6487
Epoch 65/100
1801071/1801071 - 237s - loss: 19.7497 - threeD_loss: 19.0535 - loss_1: 69.6166 - val_loss: 19.7174 - val_threeD_loss: 19.0209 - val_loss_1: 69.6484
Epoch 66/100

Epoch 00066: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-09.
1801071/1801071 - 239s - loss: 19.7495 - threeD_loss: 19.0534 - loss_1: 69.6166 - val_loss: 19.7178 - val_threeD_loss: 19.0213 - val_loss_1: 69.6485
Epoch 67/100
1801071/1801071 - 236s - loss: 19.7496 - threeD_loss: 19.0534 - loss_1: 69.6165 - val_loss: 19.7173 - val_threeD_loss: 19.0208 - val_loss_1: 69.6484
Epoch 68/100

Epoch 00068: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-10.
1801071/1801071 - 235s - loss: 19.7497 - threeD_loss: 19.0535 - loss_1: 69.6166 - val_loss: 19.7174 - val_threeD_loss: 19.0209 - val_loss_1: 69.6485
Epoch 69/100
1801071/1801071 - 236s - loss: 19.7497 - threeD_loss: 19.0535 - loss_1: 69.6167 - val_loss: 19.7174 - val_threeD_loss: 19.0209 - val_loss_1: 69.6484
Epoch 70/100

Epoch 00070: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-11.
1801071/1801071 - 235s - loss: 19.7498 - threeD_loss: 19.0537 - loss_1: 69.6166 - val_loss: 19.7178 - val_threeD_loss: 19.0213 - val_loss_1: 69.6484
Epoch 71/100
1801071/1801071 - 234s - loss: 19.7498 - threeD_loss: 19.0536 - loss_1: 69.6164 - val_loss: 19.7173 - val_threeD_loss: 19.0208 - val_loss_1: 69.6486
Epoch 72/100

Epoch 00072: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-12.
1801071/1801071 - 236s - loss: 19.7496 - threeD_loss: 19.0535 - loss_1: 69.6166 - val_loss: 19.7175 - val_threeD_loss: 19.0210 - val_loss_1: 69.6484
Epoch 73/100
1801071/1801071 - 236s - loss: 19.7497 - threeD_loss: 19.0536 - loss_1: 69.6166 - val_loss: 19.7177 - val_threeD_loss: 19.0212 - val_loss_1: 69.6485
Epoch 74/100

Epoch 00074: ReduceLROnPlateau reducing learning rate to 1.0000001044244145e-13.
1801071/1801071 - 236s - loss: 19.7496 - threeD_loss: 19.0535 - loss_1: 69.6167 - val_loss: 19.7176 - val_threeD_loss: 19.0211 - val_loss_1: 69.6484
Epoch 00074: early stopping
